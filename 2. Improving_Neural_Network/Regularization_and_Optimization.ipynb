{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad4126e",
   "metadata": {},
   "source": [
    "## train/dev/test sets\n",
    "train set: train model  \n",
    "dev set: evaluate model and change hyperparameters  \n",
    "test set: give a unbiased final performance  \n",
    "\n",
    "### ratio\n",
    "- small dataset(like 1000 or 10000): 60%/20%/20%\n",
    "- larger dataset(1,000,000): 98%/1%/1% "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45609e0c",
   "metadata": {},
   "source": [
    "## Bias and Variance\n",
    "\n",
    "<img src=\"../image/note2/bav.png\" style=\"width:70%;\">\n",
    "<img src=\"../image/note2/td.png\" style=\"width:70%;\">\n",
    "\n",
    "High bias: model performance poorly, having a high error percent  \n",
    "High variance: the error percent between training set and dev set has a significant difference  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b88b977",
   "metadata": {},
   "source": [
    "## Basic Recipe for Machine Learning\n",
    "\n",
    "1. High bias --> does not perform well on training set --> bigger network(more hidden units or layers), train longer, try new NN architectures, try advanced optimization algorithm \n",
    "\n",
    "2. High variance --> looking at dev set performance --> more data, regularization, or try more appropriate NN architecture\n",
    "\n",
    "3. Low bias and variance --> done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52792df3",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "regularization can prevent overfitting and reduce variance    \n",
    "\n",
    "L2 regularization: \n",
    "$$\n",
    "J(w, b) = \\frac{1}{m}L(\\hat{y}^{(i)}, y^{(i)}) + \\frac{\\lambda}{2m}\\|\\mathbf{w}\\|^2_2\n",
    "$$ \n",
    "where $$\\|\\mathbf{w}\\|^2_2 = w^Tw$$ \n",
    "\n",
    "meaning ***it adds the squares of all individual elements in w.*** It's called Frobenius norm.\n",
    "\n",
    "L1 regularization:\n",
    "\n",
    "changing the regularization term into\n",
    "$$\n",
    "\\frac{\\lambda}{2m}\\|\\mathbf{w}\\|_1\n",
    "$$\n",
    "\n",
    "w will become sparse, meaning w will have a lot of zeros(helps to compress model).\n",
    "\n",
    "$\\lambda$ is called regularization parameter. It is a hyperparameter.\n",
    "\n",
    "\n",
    "When doing back propogation, \n",
    "\n",
    "$dw^{[l]} = (backprop) + \\frac{\\lambda}{m}w^{[l]}$\n",
    "\n",
    "$w^{[l]} := w^{[l]} - \\alpha dw^{[l]}$\n",
    "\n",
    "$w^{[l]} := w^{[l]} - \\alpha (backprop) - \\frac{\\alpha\\lambda}{m}w^{[l]}$\n",
    "\n",
    "L2 regularization is also called weight decay.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2402fbd6",
   "metadata": {},
   "source": [
    "## How does regularization prevent overfitting?\n",
    "\n",
    "1. zeroing out some impact of hidden units  --> simplifing NN  --> change from high variance to high bias\n",
    "\n",
    "2. w decrease --> z closer to 0 --> every layer becomes closer to linear part of tanh --> solve overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1519eb30",
   "metadata": {},
   "source": [
    "## Dropout Regularization\n",
    "\n",
    "Each layer has a probability of eliminating some nodes, so eventually you can get a reduced NN, having a similar effect as regularization.  \n",
    "\n",
    "When implementing dropout, z should time keep_prob to keep the expected value of z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb3522",
   "metadata": {},
   "source": [
    "## Other Regularization Methods\n",
    "1. Data augmentation: includes additional fake trainning examples(like flipping horizontally) to reduce overfitting.  \n",
    "2. Early stopping: stop training halfway. It can prevent overfitting, but it can not get a optimized cost function.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6c6dd0",
   "metadata": {},
   "source": [
    "## Normalizing Training Sets\n",
    "1. substract out the mean: move the training set until it has a zero mean.\n",
    "$$\n",
    "\\mu = \\frac{1}{m} \\sum_{i=1}^m x^{(i)}  \n",
    "$$\n",
    "$$\n",
    "x := x - \\mu\n",
    "$$\n",
    "\n",
    "2. Nomalize variance: change both variance's height and width into 1\n",
    "$$\n",
    "\\sigma^{2} = \\frac{1}{m} \\sum_{i=1}^m x^{(i)2}\n",
    "$$\n",
    "$$\n",
    "x /= \\sigma\n",
    "$$\n",
    "\n",
    "Without normalizing data, gradient descent might oscillate. If you normalize your data, it is easier and faster to optimize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91038e8b",
   "metadata": {},
   "source": [
    "## Vanishing and Exploding Gradients\n",
    "<img src=\"../image/note2/vanishing.png\" style=\"width:70%;\">  \n",
    "\n",
    "If all the node in the graph above has a small w like 0.5, then $\\hat{y}$ will be very small, since each layer will time 0.5 to the z. If w has a value of 1.5, then $\\hat{y}$ will be very large. It also happens in back propagation, causing inefficient update of w at the initial layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759a1ea4",
   "metadata": {},
   "source": [
    "## Weight Initialization for Deep Network\n",
    "When initializing w with np.random.randn(), we should multiply by a standard deviation to make sure w is in an appropriate range, preventing gradient exlopsion or vanishing.\n",
    "- ReLU(He initialization): $\\sqrt{\\frac{2}{n^{[l-1]}}}$\n",
    "- tanh(Xavier initialization): $\\sqrt{\\frac{1}{n^{[l-1]}}}$\n",
    "- other initialization: $\\sqrt{\\frac{2}{n^{[l-1]}+n^{[l]}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c67055",
   "metadata": {},
   "source": [
    "## Numerical Approximation of Gradient\n",
    "$\\frac{f(\\theta+\\varepsilon)-f(\\theta-\\varepsilon)}{2\\varepsilon} \\approx f'(x)$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8993234",
   "metadata": {},
   "source": [
    "## Gradient Checking\n",
    "1. Take $w^{[1]}$, $b^{[1]}$, ... , $w^{[l]}$, $b^{[l]}$ and reshape into a big vector $\\theta$.\n",
    "\n",
    "2. cost function --> J($\\theta$) = J($\\theta_1$, $\\theta_2$, $\\theta_3$, ...)\n",
    "\n",
    "3. Take $dw^{[1]}$, $db^{[1]}$, ... , $dw^{[l]}$, $db^{[l]}$ and reshape into a big vector $d\\theta$.\n",
    "\n",
    "4. for each i: $d\\theta_{appox}^{[i]} = \\frac{J(\\theta_1, \\theta_2, ..., \\theta_i + \\varepsilon, ...) - J(\\theta_1, \\theta_2, ..., \\theta_i - \\varepsilon, ...)}{2\\varepsilon} \\approx \\frac{\\partial J}{\\partial\\theta_i} = d\\theta[i]$ \n",
    "\n",
    "5. compute Euclidean distance between $d\\theta[i]_{appox}$ and $d\\theta[i]$ --> $\\| \\mathbf{d\\theta}_{approx} - \\mathbf{d\\theta} \\|_2$​\n",
    "\n",
    "6. Check the ratio, the relative error by using the formula $\\frac{\\| \\mathbf{d\\theta}_{approx} - \\mathbf{d\\theta} \\|_2}{\\|{d\\theta}_{approx} \\mathbf\\|_2 + \\| d\\theta\\mathbf\\|_2}$​\n",
    "\n",
    "7. If the ratio is nearly $10^{-7}$, then it is probably correct. If the ratio is nearly $10^{-5}$, then there might be some minor errors. If the ratio is nearly $10^{-3}$, then it is incorrect.\n",
    "\n",
    "Don't use gradient checking in training, only use it in debugging.\n",
    "\n",
    "When using regularization, remember to include the reglarization term's derivative in back propagation\n",
    "\n",
    "Gradient Checking does not work with dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e5782",
   "metadata": {},
   "source": [
    "## Mini-batch gradient descent\n",
    "\n",
    "mini-batch is to divide the entire training set into several smaller training set to speed up gradient descent.\n",
    "\n",
    "$x^{\\{t\\}}$ represents $t_{th}$ mini batch\n",
    "\n",
    "<img src=\"../image/note2/minibatch.png\" style=\"width:70%;\">  \n",
    "\n",
    "mini-batch training has more oscillations, since each iteration it is training on a different mini batch: \n",
    "\n",
    "<img src=\"../image/note2/minibatchtrain.png\" style=\"width:50%;\">  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b318535",
   "metadata": {},
   "source": [
    "## Mini-batch Size\n",
    "\n",
    "- If mini-batch size = m: Batch gradient descent (too slow)\n",
    "\n",
    "- If mini-batch size = 1: Stochastic gradient descent (too much noise)\n",
    "\n",
    "- In practice: choose a size between 1 and m, because it can both use the advantages of vectorization and smaller training set\n",
    "\n",
    "#### Choose Your Mini-batch Size\n",
    "\n",
    "small training set(m <= 2000): Use batch gradient descent\n",
    "\n",
    "Typical mini-batch size: 64, 128, 256, 512, power of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16112abc",
   "metadata": {},
   "source": [
    "## Exponentially Weighted Averages\n",
    "If we want to calculate the temperature.\n",
    "\n",
    "Formula:\n",
    "\n",
    "$$V_t = \\beta V_{t-1} + (1-\\beta)\\theta_t$$\n",
    "\n",
    "where $V_t$ is approximately average over $\\frac{1}{1-\\beta}$ days' temperature.\n",
    "\n",
    "If $\\beta = 0.9$, then this formula can compute the average over the last 10 days. \n",
    "\n",
    "<img src=\"../image/note2/average.png\" style=\"width:70%;\">  \n",
    "\n",
    "the green line represent $\\beta = 0.98$ and the red line represents $\\beta = 0.9$. Having a larger $\\beta$ means having a larger weight to the previous values. Therefore, the green line adapts more slowly. On the other hand, the red line is more noisy, since it averages over a much shorter window.\n",
    "\n",
    "The v graph is a exponentially decaying graph, and this formula is just add all the values with the decaying weight from that graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6415c977",
   "metadata": {},
   "source": [
    "## Bias Correction\n",
    "\n",
    "At the beginning exponentially weighted averages, the value is underestimated since $V_0 = 0$, so we should use $\\frac{V_t}{1-\\beta^t}$ to make correction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722484b7",
   "metadata": {},
   "source": [
    "## Gradient Descent with Momentum\n",
    "<img src=\"../image/note2/momentum.png\" style=\"width:70%;\">  \n",
    "\n",
    "When doing gradient descent with momentum, the gradient descent will also consider previous gradients. Thus, there will be less oscillations.  \n",
    "\n",
    "Think gradient descent with momentum as a ball. It will accelerate at the right direction since the gradient has a consistent direction, and decelerate at unnecessary directions due to oscillations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b3cae",
   "metadata": {},
   "source": [
    "## RMSprop(root mean square prop)\n",
    "\n",
    "<img src=\"../image/note2/RMS.png\" style=\"width:70%;\">  \n",
    "\n",
    "RMSprop is used to reduce oscillations. Direction with consistently large gradient will have a large denominator, effectively lowering their learning rate, while directions that has more stable gradient get a relatively larger learning rate.\n",
    "\n",
    "epsilon pervents the term to be divided by zero or an extremely small value.\n",
    "\n",
    "The only difference between momentum and RMSprop is that RMSprop is square, so RMSprop only considers the magnitude instead of direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9a585",
   "metadata": {},
   "source": [
    "## Adam(Adaptive Moment Estimation) Optimization Algorithm\n",
    "\n",
    "$V_{dw} = 0, S_{dw} = 0, V_{db} = 0, S_{db} = 0$\n",
    "\n",
    "On iteration $t$:\n",
    "\n",
    "Compute $dw, db$ using current mini-batch\n",
    "\n",
    "$V_{dw} = \\beta_1 V_{dw} + (1-\\beta_1)dw,  V_{db} = \\beta_1 V_{db} + (1-\\beta_1)db$  <-- momentum $\\beta_1$\n",
    "\n",
    "$S_{dw} = \\beta_2 S_{dw} + (1-\\beta_2)dw^2,  S_{db} = \\beta_2 S_{db} + (1-\\beta_2)db^2$  <-- RMSprop $\\beta_2$\n",
    "\n",
    "$V_{dw}^{corrected} = \\frac{V_{dw}}{1-\\beta_1^t}, V_{db}^{corrected} = \\frac{V_{db}}{1-\\beta_1^t}$\n",
    "\n",
    "$S_{dw}^{corrected} = \\frac{S_{dw}}{1-\\beta_2^t}, S_{db}^{corrected} = \\frac{S_{db}}{1-\\beta_2^t}$\n",
    "\n",
    "$w := w - \\alpha\\frac{V_{dw}^{corr}}{\\sqrt{S_{dw}^{corr}}+\\epsilon}$\n",
    "\n",
    "$b := b - \\alpha\\frac{V_{db}^{corr}}{\\sqrt{S_{db}^{corr}}+\\epsilon}$\n",
    "\n",
    "\n",
    "#### Hyperparameter choices\n",
    "- $\\alpha$ : needs to be tune\n",
    "- $\\beta_1$ : 0.9  --> first moment\n",
    "- $\\beta_2$ : 0.999  --> second moment\n",
    "- $\\epsilon$ : $10^{-8}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8dba08",
   "metadata": {},
   "source": [
    "## Learning Rate Decay\n",
    "Fixed value of $\\alpha$ will not converge very well. A smaller learning rate will end up oscillating in a tight region around the minimum.\n",
    "\n",
    "1 epoch = 1 pass through all data\n",
    "\n",
    "$\\alpha = \\frac{1}{1+\\text{decayrate} * epoch_{num}} \\alpha_0$\n",
    "\n",
    "$\\alpha = 0.95^{epoch_{num}} * \\alpha_0$  <-- exponential decay\n",
    "\n",
    "$\\alpha = \\frac{k}{\\sqrt{epoch_{num}}} * \\alpha_0$\n",
    "\n",
    "or discrete staircase"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
